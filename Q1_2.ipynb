{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Speaker Scenario Dataset Creation and Evaluation\n",
    "The second part of the assignment shifts focus to multi-speaker scenarios, involving the creation of a custom dataset and the evaluation of both speaker separation and identification tasks using advanced models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T20:16:36.675617Z",
     "iopub.status.busy": "2025-04-02T20:16:36.675161Z",
     "iopub.status.idle": "2025-04-02T20:16:42.578220Z",
     "shell.execute_reply": "2025-04-02T20:16:42.576963Z",
     "shell.execute_reply.started": "2025-04-02T20:16:36.675566Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install speechbrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T20:16:50.999589Z",
     "iopub.status.busy": "2025-04-02T20:16:50.999297Z",
     "iopub.status.idle": "2025-04-02T20:17:02.812683Z",
     "shell.execute_reply": "2025-04-02T20:17:02.811815Z",
     "shell.execute_reply.started": "2025-04-02T20:16:50.999563Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install pesq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T20:17:17.812783Z",
     "iopub.status.busy": "2025-04-02T20:17:17.812359Z",
     "iopub.status.idle": "2025-04-02T20:17:21.629771Z",
     "shell.execute_reply": "2025-04-02T20:17:21.628606Z",
     "shell.execute_reply.started": "2025-04-02T20:17:17.812744Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install mir-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:30.242914Z",
     "iopub.status.busy": "2025-04-02T21:01:30.242576Z",
     "iopub.status.idle": "2025-04-02T21:01:30.317993Z",
     "shell.execute_reply": "2025-04-02T21:01:30.317350Z",
     "shell.execute_reply.started": "2025-04-02T21:01:30.242883Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from speechbrain.pretrained import SepformerSeparation\n",
    "from mir_eval.separation import bss_eval_sources\n",
    "from pesq import pesq\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:31.948079Z",
     "iopub.status.busy": "2025-04-02T21:01:31.947765Z",
     "iopub.status.idle": "2025-04-02T21:01:31.953154Z",
     "shell.execute_reply": "2025-04-02T21:01:31.952250Z",
     "shell.execute_reply.started": "2025-04-02T21:01:31.948053Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:33.164368Z",
     "iopub.status.busy": "2025-04-02T21:01:33.164074Z",
     "iopub.status.idle": "2025-04-02T21:01:33.168312Z",
     "shell.execute_reply": "2025-04-02T21:01:33.167154Z",
     "shell.execute_reply.started": "2025-04-02T21:01:33.164345Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "VOXCELEB2_TXT_BASE_DIR = \"/kaggle/input/vox2celebtext/txt\"\n",
    "VOXCELEB2_AUDIO_BASE_DIR = \"/kaggle/input/voxcelebdataset-su/vox2_test_aac/aac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:17:36.336041Z",
     "iopub.status.busy": "2025-04-02T20:17:36.335695Z",
     "iopub.status.idle": "2025-04-02T20:17:36.339640Z",
     "shell.execute_reply": "2025-04-02T20:17:36.338769Z",
     "shell.execute_reply.started": "2025-04-02T20:17:36.336004Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TARGET_SAMPLE_RATE = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:36.200167Z",
     "iopub.status.busy": "2025-04-02T21:01:36.199841Z",
     "iopub.status.idle": "2025-04-02T21:01:36.203796Z",
     "shell.execute_reply": "2025-04-02T21:01:36.202855Z",
     "shell.execute_reply.started": "2025-04-02T21:01:36.200138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TARGET_SAMPLE_RATE_16 = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:37.642899Z",
     "iopub.status.busy": "2025-04-02T21:01:37.642538Z",
     "iopub.status.idle": "2025-04-02T21:01:37.648668Z",
     "shell.execute_reply": "2025-04-02T21:01:37.647719Z",
     "shell.execute_reply.started": "2025-04-02T21:01:37.642867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_voxceleb_metadata(txt_base_dir, audio_base_dir):\n",
    "    \n",
    "    speaker_dict = {}\n",
    "    pattern = os.path.join(txt_base_dir, \"**\", \"*.txt\")\n",
    "    txt_files = glob.glob(pattern, recursive=True)\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        rel_path = os.path.relpath(txt_file, txt_base_dir)\n",
    "        parts = rel_path.split(os.sep)\n",
    "        if len(parts) < 3:\n",
    "            continue  \n",
    "        \n",
    "        speaker_id = parts[0]\n",
    "        recording_id = parts[1]\n",
    "        file_name = parts[2]\n",
    "        audio_file = os.path.join(audio_base_dir, speaker_id, recording_id, file_name.replace('.txt', '.m4a'))\n",
    "        if not os.path.exists(audio_file):\n",
    "            continue\n",
    "        \n",
    "        if speaker_id not in speaker_dict:\n",
    "            speaker_dict[speaker_id] = []\n",
    "        speaker_dict[speaker_id].append(audio_file)\n",
    "    \n",
    "    return speaker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:39.335342Z",
     "iopub.status.busy": "2025-04-02T21:01:39.335054Z",
     "iopub.status.idle": "2025-04-02T21:01:39.339514Z",
     "shell.execute_reply": "2025-04-02T21:01:39.338613Z",
     "shell.execute_reply.started": "2025-04-02T21:01:39.335319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def resample_audio(audio, orig_sr, target_sr):\n",
    "    if orig_sr != target_sr:\n",
    "        transform = torchaudio.transforms.Resample(orig_sr, target_sr)\n",
    "        audio = transform(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:40.244601Z",
     "iopub.status.busy": "2025-04-02T21:01:40.244306Z",
     "iopub.status.idle": "2025-04-02T21:01:40.249025Z",
     "shell.execute_reply": "2025-04-02T21:01:40.248177Z",
     "shell.execute_reply.started": "2025-04-02T21:01:40.244577Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_audio_file(file_path, target_sr=TARGET_SAMPLE_RATE):\n",
    "    \n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    audio = resample_audio(audio, sr, target_sr)\n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:41.661711Z",
     "iopub.status.busy": "2025-04-02T21:01:41.661414Z",
     "iopub.status.idle": "2025-04-02T21:01:41.666493Z",
     "shell.execute_reply": "2025-04-02T21:01:41.665704Z",
     "shell.execute_reply.started": "2025-04-02T21:01:41.661679Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def pad_or_truncate(aud1, aud2):\n",
    "    len1 = aud1.shape[1]\n",
    "    len2 = aud2.shape[1]\n",
    "    if len1 < len2:\n",
    "        pad = torch.zeros(1, len2 - len1)\n",
    "        aud1 = torch.cat([aud1, pad], dim=1)\n",
    "    elif len2 < len1:\n",
    "        pad = torch.zeros(1, len1 - len2)\n",
    "        aud2 = torch.cat([aud2, pad], dim=1)\n",
    "    return aud1, aud2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:43.062208Z",
     "iopub.status.busy": "2025-04-02T21:01:43.061805Z",
     "iopub.status.idle": "2025-04-02T21:01:43.068379Z",
     "shell.execute_reply": "2025-04-02T21:01:43.067500Z",
     "shell.execute_reply.started": "2025-04-02T21:01:43.062178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def mix_utterances(utt1, utt2, snr_dB=0):\n",
    "    \n",
    "    utt1, utt2 = pad_or_truncate(utt1, utt2)\n",
    "    power1 = utt1.pow(2).mean()\n",
    "    power2 = utt2.pow(2).mean()\n",
    "    scale = torch.sqrt(power1 / (10**(snr_dB/10) * power2 + 1e-8))\n",
    "    utt2_scaled = utt2 * scale\n",
    "    mixture = utt1 + utt2_scaled\n",
    "    return mixture, utt1, utt2_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:44.455749Z",
     "iopub.status.busy": "2025-04-02T21:01:44.455424Z",
     "iopub.status.idle": "2025-04-02T21:01:44.460654Z",
     "shell.execute_reply": "2025-04-02T21:01:44.459778Z",
     "shell.execute_reply.started": "2025-04-02T21:01:44.455721Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_metrics(ref_sources, est_sources, sample_rate):\n",
    "    SDR, SIR, SAR, _ = bss_eval_sources(ref_sources, est_sources)\n",
    "    pesq_mode = \"nb\" if sample_rate == 8000 else \"wb\"\n",
    "\n",
    "    pesq_scores = []\n",
    "    for i in range(ref_sources.shape[0]):\n",
    "        score = pesq(sample_rate, ref_sources[i], est_sources[i], mode=pesq_mode)\n",
    "        pesq_scores.append(score)\n",
    "\n",
    "    return SDR, SIR, SAR, pesq_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:47.045160Z",
     "iopub.status.busy": "2025-04-02T21:01:47.044797Z",
     "iopub.status.idle": "2025-04-02T21:01:47.050711Z",
     "shell.execute_reply": "2025-04-02T21:01:47.049864Z",
     "shell.execute_reply.started": "2025-04-02T21:01:47.045132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_scenario(speaker_dict, speaker_ids, num_mixtures=500):\n",
    "    \n",
    "    mixtures = []\n",
    "    available_speakers = [s for s in speaker_ids if s in speaker_dict and len(speaker_dict[s]) > 0]\n",
    "    if len(available_speakers) < 2:\n",
    "        raise ValueError(\"Need at least two speakers to create mixtures.\")\n",
    "\n",
    "    for _ in range(num_mixtures):\n",
    "        spk1, spk2 = random.sample(available_speakers, 2)\n",
    "        utt1_path = random.choice(speaker_dict[spk1])\n",
    "        utt2_path = random.choice(speaker_dict[spk2])\n",
    "        utt1 = load_audio_file(utt1_path)\n",
    "        utt2 = load_audio_file(utt2_path)\n",
    "        mixture, ref1, ref2 = mix_utterances(utt1, utt2, snr_dB=0)\n",
    "\n",
    "        mixtures.append((mixture, [ref1, ref2], [spk1, spk2]))\n",
    "\n",
    "    return mixtures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:28:00.817303Z",
     "iopub.status.busy": "2025-04-02T20:28:00.817006Z",
     "iopub.status.idle": "2025-04-02T20:28:00.821997Z",
     "shell.execute_reply": "2025-04-02T20:28:00.820958Z",
     "shell.execute_reply.started": "2025-04-02T20:28:00.817278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "\n",
    "def best_permutation_match(ref_sources, est_sources, sample_rate):\n",
    "    best_sdr = -float('inf')\n",
    "    best_perm = None\n",
    "    \n",
    "    for perm in permutations([0, 1]):  \n",
    "        perm_est_sources = est_sources[list(perm), :]\n",
    "        SDR, _, _, _ = evaluate_metrics(ref_sources, perm_est_sources, sample_rate)\n",
    "        total_sdr = sum(SDR)  \n",
    "        \n",
    "        if total_sdr > best_sdr:\n",
    "            best_sdr = total_sdr\n",
    "            best_perm = perm\n",
    "    \n",
    "    return best_perm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:51.823730Z",
     "iopub.status.busy": "2025-04-02T21:01:51.823392Z",
     "iopub.status.idle": "2025-04-02T21:01:51.830252Z",
     "shell.execute_reply": "2025-04-02T21:01:51.829451Z",
     "shell.execute_reply.started": "2025-04-02T21:01:51.823700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_separation_and_evaluation(mixtures, model, sample_rate, save_dir=\"separated_audio\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    metrics_results = []\n",
    "    \n",
    "    for idx, (mixture, refs, spk_ids) in enumerate(tqdm(mixtures, desc=\"Processing mixtures\")):\n",
    "        temp_filename = f\"temp_mixture_{idx}.wav\"\n",
    "        torchaudio.save(temp_filename, mixture, sample_rate)\n",
    "\n",
    "        mix_tensor, sr = torchaudio.load(temp_filename)\n",
    "        separated = model.separate_batch(mix_tensor)\n",
    "\n",
    "        ref_sources = np.array([s.squeeze().numpy() for s in refs])  # (2, samples)\n",
    "        est_sources = separated.cpu().numpy().squeeze(0).T  # (2, samples)\n",
    "\n",
    "        best_perm = best_permutation_match(ref_sources, est_sources, sample_rate)\n",
    "        est_sources = est_sources[list(best_perm), :]  # Reorder estimated sources\n",
    "\n",
    "        for spk_idx, (est_source, spk_id) in enumerate(zip(est_sources, spk_ids)):\n",
    "            spk_save_path = os.path.join(save_dir, f\"spk_{spk_id}_sep_{idx}.wav\")\n",
    "            torchaudio.save(spk_save_path, torch.tensor(est_source).unsqueeze(0), sample_rate)\n",
    "\n",
    "        SDR, SIR, SAR, pesq_scores = evaluate_metrics(ref_sources, est_sources, sample_rate)\n",
    "        metrics_results.append({\n",
    "            \"SDR\": SDR,\n",
    "            \"SIR\": SIR,\n",
    "            \"SAR\": SAR,\n",
    "            \"PESQ\": pesq_scores\n",
    "        })\n",
    "\n",
    "        os.remove(temp_filename)\n",
    "\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:01:55.334494Z",
     "iopub.status.busy": "2025-04-02T21:01:55.334160Z",
     "iopub.status.idle": "2025-04-02T21:03:23.293561Z",
     "shell.execute_reply": "2025-04-02T21:03:23.292798Z",
     "shell.execute_reply.started": "2025-04-02T21:01:55.334463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata...\n",
      "Total speakers found: 118\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading metadata...\")\n",
    "speaker_dict = load_voxceleb_metadata(VOXCELEB2_TXT_BASE_DIR, VOXCELEB2_AUDIO_BASE_DIR)\n",
    "all_speakers = sorted(list(speaker_dict.keys()))\n",
    "print(f\"Total speakers found: {len(all_speakers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:28:45.980266Z",
     "iopub.status.busy": "2025-04-02T20:28:45.979982Z",
     "iopub.status.idle": "2025-04-02T20:28:45.985194Z",
     "shell.execute_reply": "2025-04-02T20:28:45.984291Z",
     "shell.execute_reply.started": "2025-04-02T20:28:45.980242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training speakers: 50, Testing speakers: 100\n"
     ]
    }
   ],
   "source": [
    "train_ids = all_speakers[:50]\n",
    "test_ids = all_speakers[:100]\n",
    "print(f\"Training speakers: {len(train_ids)}, Testing speakers: {len(test_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T20:28:57.476243Z",
     "iopub.status.busy": "2025-04-02T20:28:57.475915Z",
     "iopub.status.idle": "2025-04-02T20:29:10.789743Z",
     "shell.execute_reply": "2025-04-02T20:29:10.788852Z",
     "shell.execute_reply.started": "2025-04-02T20:28:57.476211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating testing scenario mixtures...\n",
      "Created\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating testing scenario mixtures...\")\n",
    "test_mixtures = create_scenario(speaker_dict, test_ids)\n",
    "print(\"Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:03:38.354475Z",
     "iopub.status.busy": "2025-04-02T21:03:38.354176Z",
     "iopub.status.idle": "2025-04-02T21:03:39.346257Z",
     "shell.execute_reply": "2025-04-02T21:03:39.345558Z",
     "shell.execute_reply.started": "2025-04-02T21:03:38.354452Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained SepFormer model...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading pre-trained SepFormer model...\")\n",
    "sepformer_model = SepformerSeparation.from_hparams(\"speechbrain/sepformer-wsj02mix\",run_opts={\"device\":\"cuda\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:03:48.032970Z",
     "iopub.status.busy": "2025-04-02T21:03:48.032622Z",
     "iopub.status.idle": "2025-04-02T21:22:52.765128Z",
     "shell.execute_reply": "2025-04-02T21:22:52.764373Z",
     "shell.execute_reply.started": "2025-04-02T21:03:48.032940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing separation and evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing mixtures:   0%|          | 0/500 [00:00<?, ?it/s]<ipython-input-82-14e5f843f697>:5: FutureWarning: mir_eval.separation.bss_eval_sources\n",
      "\tDeprecated as of mir_eval version 0.8.\n",
      "\tIt will be removed in mir_eval version 0.9.\n",
      "  SDR, SIR, SAR, _ = bss_eval_sources(ref_sources, est_sources)\n",
      "Processing mixtures: 100%|██████████| 500/500 [19:04<00:00,  2.29s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Performing separation and evaluation...\")\n",
    "metrics_results = run_separation_and_evaluation(test_mixtures, sepformer_model, TARGET_SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:22:56.975033Z",
     "iopub.status.busy": "2025-04-02T21:22:56.974716Z",
     "iopub.status.idle": "2025-04-02T21:22:56.984337Z",
     "shell.execute_reply": "2025-04-02T21:22:56.983622Z",
     "shell.execute_reply.started": "2025-04-02T21:22:56.975008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Results (Average over mixtures) ---\n",
      "Average SDR: 8.79 dB\n",
      "Average SIR: 14.83 dB\n",
      "Average SAR: 11.61 dB\n",
      "Average PESQ: 2.01\n"
     ]
    }
   ],
   "source": [
    "all_SDR = np.concatenate([res[\"SDR\"] for res in metrics_results])\n",
    "all_SIR = np.concatenate([res[\"SIR\"] for res in metrics_results])\n",
    "all_SAR = np.concatenate([res[\"SAR\"] for res in metrics_results])\n",
    "all_PESQ = np.concatenate([res[\"PESQ\"] for res in metrics_results])\n",
    "    \n",
    "print(\"\\n--- Evaluation Results (Average over mixtures) ---\")\n",
    "print(f\"Average SDR: {np.mean(all_SDR):.2f} dB\")\n",
    "print(f\"Average SIR: {np.mean(all_SIR):.2f} dB\")\n",
    "print(f\"Average SAR: {np.mean(all_SAR):.2f} dB\")\n",
    "print(f\"Average PESQ: {np.mean(all_PESQ):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:02.339500Z",
     "iopub.status.busy": "2025-04-02T21:23:02.339186Z",
     "iopub.status.idle": "2025-04-02T21:23:02.344010Z",
     "shell.execute_reply": "2025-04-02T21:23:02.342892Z",
     "shell.execute_reply.started": "2025-04-02T21:23:02.339471Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def resample_audio_16(audio, orig_sr, target_sr=16000):\n",
    "    if orig_sr != target_sr:\n",
    "        transform = torchaudio.transforms.Resample(orig_sr, target_sr)\n",
    "        audio = transform(audio)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:03.746908Z",
     "iopub.status.busy": "2025-04-02T21:23:03.746600Z",
     "iopub.status.idle": "2025-04-02T21:23:03.751229Z",
     "shell.execute_reply": "2025-04-02T21:23:03.750400Z",
     "shell.execute_reply.started": "2025-04-02T21:23:03.746881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_audio_file_16(file_path):\n",
    "    audio, sr = torchaudio.load(file_path)\n",
    "    target_sr = 16000\n",
    "    audio = resample_audio_16(audio, sr, target_sr=16000)\n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T21:16:30.575935Z",
     "iopub.status.busy": "2025-04-01T21:16:30.575605Z",
     "iopub.status.idle": "2025-04-01T21:16:30.581356Z",
     "shell.execute_reply": "2025-04-01T21:16:30.580506Z",
     "shell.execute_reply.started": "2025-04-01T21:16:30.575910Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_scenario_with_labels(speaker_dict, speaker_ids, num_mixtures=100):\n",
    "    mixtures = []\n",
    "    available_speakers = [s for s in speaker_ids if s in speaker_dict and len(speaker_dict[s]) > 0]\n",
    "    if len(available_speakers) < 2:\n",
    "        raise ValueError(\"Need at least two speakers to create mixtures.\")\n",
    "    \n",
    "    for _ in range(num_mixtures):\n",
    "        spk1, spk2 = random.sample(available_speakers, 2)\n",
    "        utt1_path = random.choice(speaker_dict[spk1])\n",
    "        utt2_path = random.choice(speaker_dict[spk2])\n",
    "        utt1 = load_audio_file_16(utt1_path)\n",
    "        utt2 = load_audio_file_16(utt2_path)\n",
    "        mixture, ref1, ref2 = mix_utterances(utt1, utt2, snr_dB=0)\n",
    "        mixtures.append((mixture, [ref1, ref2], [spk1, spk2]))\n",
    "    return mixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:14.081006Z",
     "iopub.status.busy": "2025-04-02T21:23:14.080653Z",
     "iopub.status.idle": "2025-04-02T21:23:14.086832Z",
     "shell.execute_reply": "2025-04-02T21:23:14.085905Z",
     "shell.execute_reply.started": "2025-04-02T21:23:14.080975Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spk_id02542_sep_261.wav', 'spk_id07312_sep_442.wav', 'spk_id01822_sep_3.wav', 'spk_id01224_sep_318.wav', 'spk_id01224_sep_1.wav', 'spk_id04295_sep_159.wav', 'spk_id06913_sep_103.wav', 'spk_id00419_sep_112.wav', 'spk_id00419_sep_113.wav', 'spk_id01541_sep_128.wav', 'spk_id00866_sep_63.wav', 'spk_id01228_sep_306.wav', 'spk_id01106_sep_466.wav', 'spk_id05459_sep_133.wav', 'spk_id00812_sep_106.wav', 'spk_id01460_sep_379.wav', 'spk_id00017_sep_449.wav', 'spk_id02181_sep_274.wav', 'spk_id01509_sep_132.wav', 'spk_id01066_sep_499.wav', 'spk_id03030_sep_27.wav', 'spk_id05594_sep_254.wav', 'spk_id06811_sep_385.wav', 'spk_id02725_sep_308.wav', 'spk_id06310_sep_181.wav', 'spk_id00562_sep_62.wav', 'spk_id02019_sep_77.wav', 'spk_id03127_sep_184.wav', 'spk_id01333_sep_48.wav', 'spk_id01000_sep_3.wav', 'spk_id03980_sep_118.wav', 'spk_id03382_sep_26.wav', 'spk_id04627_sep_64.wav', 'spk_id00017_sep_149.wav', 'spk_id01593_sep_356.wav', 'spk_id03524_sep_53.wav', 'spk_id01333_sep_44.wav', 'spk_id05816_sep_478.wav', 'spk_id01989_sep_173.wav', 'spk_id02548_sep_167.wav', 'spk_id04950_sep_55.wav', 'spk_id01437_sep_315.wav', 'spk_id01541_sep_430.wav', 'spk_id07354_sep_354.wav', 'spk_id04950_sep_360.wav', 'spk_id03981_sep_332.wav', 'spk_id01066_sep_117.wav', 'spk_id03382_sep_9.wav', 'spk_id01000_sep_186.wav', 'spk_id02086_sep_257.wav', 'spk_id04366_sep_148.wav', 'spk_id04570_sep_207.wav', 'spk_id01541_sep_348.wav', 'spk_id00926_sep_432.wav', 'spk_id04030_sep_488.wav', 'spk_id03981_sep_396.wav', 'spk_id06811_sep_252.wav', 'spk_id04656_sep_200.wav', 'spk_id04006_sep_97.wav', 'spk_id07312_sep_158.wav', 'spk_id02576_sep_26.wav', 'spk_id02465_sep_14.wav', 'spk_id02086_sep_356.wav', 'spk_id04253_sep_267.wav', 'spk_id07396_sep_198.wav', 'spk_id05015_sep_28.wav', 'spk_id02057_sep_476.wav', 'spk_id01000_sep_390.wav', 'spk_id01437_sep_332.wav', 'spk_id01000_sep_66.wav', 'spk_id04276_sep_387.wav', 'spk_id02317_sep_10.wav', 'spk_id01460_sep_260.wav', 'spk_id01000_sep_388.wav', 'spk_id01618_sep_99.wav', 'spk_id00926_sep_137.wav', 'spk_id05055_sep_312.wav', 'spk_id03347_sep_208.wav', 'spk_id02286_sep_355.wav', 'spk_id07354_sep_274.wav', 'spk_id05459_sep_214.wav', 'spk_id05999_sep_474.wav', 'spk_id04536_sep_400.wav', 'spk_id02685_sep_17.wav', 'spk_id06913_sep_435.wav', 'spk_id07396_sep_164.wav', 'spk_id01567_sep_401.wav', 'spk_id05202_sep_203.wav', 'spk_id01892_sep_441.wav', 'spk_id01567_sep_438.wav', 'spk_id01333_sep_338.wav', 'spk_id06811_sep_236.wav', 'spk_id03789_sep_84.wav', 'spk_id05714_sep_216.wav', 'spk_id04232_sep_167.wav', 'spk_id00812_sep_5.wav', 'spk_id03524_sep_154.wav', 'spk_id00419_sep_176.wav', 'spk_id04656_sep_190.wav', 'spk_id03041_sep_459.wav', 'spk_id07414_sep_4.wav', 'spk_id00061_sep_11.wav', 'spk_id00017_sep_141.wav', 'spk_id03839_sep_83.wav', 'spk_id07312_sep_360.wav', 'spk_id03862_sep_157.wav', 'spk_id01228_sep_271.wav', 'spk_id02445_sep_265.wav', 'spk_id01066_sep_100.wav', 'spk_id01509_sep_420.wav', 'spk_id01822_sep_99.wav', 'spk_id01989_sep_404.wav', 'spk_id02548_sep_342.wav', 'spk_id04366_sep_423.wav', 'spk_id03789_sep_310.wav', 'spk_id02317_sep_422.wav', 'spk_id04094_sep_41.wav', 'spk_id02685_sep_251.wav', 'spk_id03978_sep_487.wav', 'spk_id01224_sep_130.wav', 'spk_id03178_sep_300.wav', 'spk_id07414_sep_151.wav', 'spk_id01593_sep_137.wav', 'spk_id02542_sep_292.wav', 'spk_id03862_sep_180.wav', 'spk_id07414_sep_361.wav', 'spk_id04657_sep_323.wav', 'spk_id03127_sep_86.wav', 'spk_id03382_sep_29.wav', 'spk_id01509_sep_491.wav', 'spk_id06209_sep_498.wav', 'spk_id06104_sep_448.wav', 'spk_id04006_sep_296.wav', 'spk_id02725_sep_407.wav', 'spk_id04253_sep_241.wav', 'spk_id04862_sep_275.wav', 'spk_id06484_sep_32.wav', 'spk_id02576_sep_170.wav', 'spk_id03789_sep_43.wav', 'spk_id04657_sep_263.wav', 'spk_id06310_sep_455.wav', 'spk_id01066_sep_109.wav', 'spk_id02086_sep_416.wav', 'spk_id00154_sep_399.wav', 'spk_id01567_sep_396.wav', 'spk_id06484_sep_228.wav', 'spk_id03382_sep_269.wav', 'spk_id07312_sep_423.wav', 'spk_id05015_sep_102.wav', 'spk_id02685_sep_451.wav', 'spk_id02057_sep_193.wav', 'spk_id03524_sep_219.wav', 'spk_id02181_sep_252.wav', 'spk_id03030_sep_314.wav', 'spk_id05015_sep_74.wav', 'spk_id04656_sep_325.wav', 'spk_id07354_sep_391.wav', 'spk_id05714_sep_138.wav', 'spk_id02445_sep_282.wav', 'spk_id02576_sep_38.wav', 'spk_id03839_sep_152.wav', 'spk_id02086_sep_75.wav', 'spk_id03127_sep_49.wav', 'spk_id00866_sep_158.wav', 'spk_id00419_sep_11.wav', 'spk_id00419_sep_120.wav', 'spk_id02465_sep_488.wav', 'spk_id05459_sep_450.wav', 'spk_id04094_sep_493.wav', 'spk_id05654_sep_367.wav', 'spk_id06209_sep_118.wav', 'spk_id02317_sep_370.wav', 'spk_id00866_sep_206.wav', 'spk_id01224_sep_128.wav', 'spk_id05176_sep_473.wav', 'spk_id02745_sep_245.wav', 'spk_id01892_sep_455.wav', 'spk_id06104_sep_146.wav', 'spk_id01593_sep_200.wav', 'spk_id02086_sep_138.wav', 'spk_id03839_sep_198.wav', 'spk_id03839_sep_384.wav', 'spk_id04950_sep_251.wav', 'spk_id01593_sep_278.wav', 'spk_id00926_sep_453.wav', 'spk_id03524_sep_486.wav', 'spk_id06811_sep_316.wav', 'spk_id01822_sep_239.wav', 'spk_id00562_sep_1.wav', 'spk_id02548_sep_402.wav', 'spk_id02685_sep_20.wav', 'spk_id01989_sep_337.wav', 'spk_id00817_sep_92.wav', 'spk_id03178_sep_82.wav', 'spk_id04276_sep_230.wav', 'spk_id05202_sep_284.wav', 'spk_id05459_sep_346.wav', 'spk_id03839_sep_473.wav', 'spk_id00562_sep_175.wav', 'spk_id03862_sep_297.wav', 'spk_id02548_sep_495.wav', 'spk_id01822_sep_180.wav', 'spk_id02317_sep_31.wav', 'spk_id03978_sep_315.wav', 'spk_id02548_sep_225.wav', 'spk_id04657_sep_35.wav', 'spk_id01567_sep_324.wav', 'spk_id02685_sep_344.wav', 'spk_id07354_sep_81.wav', 'spk_id04276_sep_397.wav', 'spk_id06692_sep_89.wav', 'spk_id01298_sep_475.wav', 'spk_id06692_sep_160.wav', 'spk_id05124_sep_401.wav', 'spk_id03978_sep_178.wav', 'spk_id02685_sep_157.wav', 'spk_id01989_sep_13.wav', 'spk_id07414_sep_205.wav', 'spk_id05015_sep_37.wav', 'spk_id00061_sep_312.wav', 'spk_id02086_sep_393.wav', 'spk_id04119_sep_44.wav', 'spk_id01333_sep_460.wav', 'spk_id05816_sep_189.wav', 'spk_id01066_sep_172.wav', 'spk_id02086_sep_463.wav', 'spk_id04478_sep_395.wav', 'spk_id04119_sep_246.wav', 'spk_id06816_sep_361.wav', 'spk_id01509_sep_42.wav', 'spk_id02465_sep_114.wav', 'spk_id06692_sep_20.wav', 'spk_id01822_sep_60.wav', 'spk_id00081_sep_240.wav', 'spk_id06692_sep_365.wav', 'spk_id06913_sep_53.wav', 'spk_id05055_sep_371.wav', 'spk_id00926_sep_493.wav', 'spk_id04950_sep_218.wav', 'spk_id03347_sep_107.wav', 'spk_id03677_sep_340.wav', 'spk_id06913_sep_336.wav', 'spk_id01041_sep_406.wav', 'spk_id05459_sep_232.wav', 'spk_id01989_sep_61.wav', 'spk_id01989_sep_368.wav', 'spk_id00017_sep_51.wav', 'spk_id01989_sep_239.wav', 'spk_id07426_sep_25.wav', 'spk_id03041_sep_400.wav', 'spk_id05202_sep_2.wav', 'spk_id04657_sep_28.wav', 'spk_id05055_sep_435.wav', 'spk_id05714_sep_131.wav', 'spk_id02317_sep_283.wav', 'spk_id01541_sep_12.wav', 'spk_id01066_sep_482.wav', 'spk_id06913_sep_325.wav', 'spk_id05999_sep_17.wav', 'spk_id03978_sep_0.wav', 'spk_id03981_sep_405.wav', 'spk_id03524_sep_174.wav', 'spk_id00081_sep_345.wav', 'spk_id07396_sep_279.wav', 'spk_id03969_sep_101.wav', 'spk_id02086_sep_417.wav', 'spk_id05459_sep_352.wav', 'spk_id03981_sep_335.wav', 'spk_id01333_sep_136.wav', 'spk_id05202_sep_338.wav', 'spk_id00562_sep_39.wav', 'spk_id01298_sep_15.wav', 'spk_id04627_sep_27.wav', 'spk_id03030_sep_496.wav', 'spk_id01822_sep_192.wav', 'spk_id04119_sep_302.wav', 'spk_id02181_sep_103.wav', 'spk_id00817_sep_181.wav', 'spk_id00081_sep_347.wav', 'spk_id04536_sep_349.wav', 'spk_id05124_sep_250.wav', 'spk_id04253_sep_43.wav', 'spk_id07426_sep_166.wav', 'spk_id06913_sep_155.wav', 'spk_id00419_sep_347.wav', 'spk_id03127_sep_249.wav', 'spk_id01106_sep_218.wav', 'spk_id04276_sep_337.wav', 'spk_id06692_sep_295.wav', 'spk_id02576_sep_196.wav', 'spk_id02465_sep_428.wav', 'spk_id04276_sep_378.wav', 'spk_id03789_sep_326.wav', 'spk_id05816_sep_120.wav', 'spk_id04536_sep_317.wav', 'spk_id03978_sep_464.wav', 'spk_id02057_sep_123.wav', 'spk_id05850_sep_342.wav', 'spk_id00154_sep_149.wav', 'spk_id00812_sep_290.wav', 'spk_id06913_sep_289.wav', 'spk_id02019_sep_148.wav', 'spk_id03041_sep_18.wav', 'spk_id03839_sep_278.wav', 'spk_id05850_sep_52.wav', 'spk_id03969_sep_380.wav', 'spk_id05015_sep_452.wav', 'spk_id04478_sep_363.wav', 'spk_id02725_sep_436.wav', 'spk_id07414_sep_96.wav', 'spk_id01892_sep_111.wav', 'spk_id01989_sep_358.wav', 'spk_id04536_sep_380.wav', 'spk_id04366_sep_253.wav', 'spk_id06811_sep_458.wav', 'spk_id02317_sep_182.wav', 'spk_id00017_sep_201.wav', 'spk_id05176_sep_304.wav', 'spk_id01989_sep_115.wav', 'spk_id04030_sep_73.wav', 'spk_id03041_sep_316.wav', 'spk_id02577_sep_485.wav', 'spk_id04657_sep_392.wav', 'spk_id05999_sep_412.wav', 'spk_id03524_sep_38.wav', 'spk_id01298_sep_62.wav', 'spk_id02542_sep_41.wav', 'spk_id05816_sep_415.wav', 'spk_id03677_sep_225.wav', 'spk_id04570_sep_15.wav', 'spk_id02685_sep_234.wav', 'spk_id04627_sep_311.wav', 'spk_id07312_sep_382.wav', 'spk_id01892_sep_140.wav', 'spk_id02577_sep_206.wav', 'spk_id04366_sep_91.wav', 'spk_id01298_sep_54.wav', 'spk_id03978_sep_343.wav', 'spk_id00812_sep_408.wav', 'spk_id02019_sep_242.wav', 'spk_id06104_sep_279.wav', 'spk_id00154_sep_306.wav', 'spk_id01989_sep_226.wav', 'spk_id03041_sep_267.wav', 'spk_id04119_sep_85.wav', 'spk_id00562_sep_7.wav', 'spk_id01000_sep_55.wav', 'spk_id05850_sep_364.wav', 'spk_id02548_sep_476.wav', 'spk_id03862_sep_77.wav', 'spk_id06811_sep_339.wav', 'spk_id01541_sep_307.wav', 'spk_id06913_sep_4.wav', 'spk_id03524_sep_136.wav', 'spk_id05850_sep_301.wav', 'spk_id00812_sep_191.wav', 'spk_id04366_sep_444.wav', 'spk_id04862_sep_446.wav', 'spk_id06811_sep_98.wav', 'spk_id02086_sep_57.wav', 'spk_id03978_sep_215.wav', 'spk_id02725_sep_430.wav', 'spk_id04657_sep_133.wav', 'spk_id04950_sep_353.wav', 'spk_id05459_sep_187.wav', 'spk_id04366_sep_23.wav', 'spk_id02725_sep_497.wav', 'spk_id03524_sep_374.wav', 'spk_id06913_sep_319.wav', 'spk_id01892_sep_443.wav', 'spk_id03178_sep_280.wav', 'spk_id00562_sep_142.wav', 'spk_id06913_sep_255.wav', 'spk_id00419_sep_439.wav', 'spk_id03677_sep_458.wav', 'spk_id02685_sep_212.wav', 'spk_id02465_sep_266.wav', 'spk_id07396_sep_122.wav', 'spk_id01041_sep_88.wav', 'spk_id01892_sep_195.wav', 'spk_id02086_sep_497.wav', 'spk_id04253_sep_171.wav', 'spk_id06816_sep_454.wav', 'spk_id05816_sep_139.wav', 'spk_id04570_sep_320.wav', 'spk_id02445_sep_194.wav', 'spk_id01041_sep_270.wav', 'spk_id04253_sep_330.wav', 'spk_id05459_sep_185.wav', 'spk_id02542_sep_341.wav', 'spk_id07312_sep_22.wav', 'spk_id00926_sep_490.wav', 'spk_id02745_sep_265.wav', 'spk_id06484_sep_432.wav', 'spk_id06811_sep_305.wav', 'spk_id01822_sep_352.wav', 'spk_id05015_sep_294.wav', 'spk_id01333_sep_90.wav', 'spk_id02542_sep_468.wav', 'spk_id02057_sep_413.wav', 'spk_id04657_sep_23.wav', 'spk_id00419_sep_484.wav', 'spk_id02542_sep_213.wav', 'spk_id04570_sep_161.wav', 'spk_id01066_sep_60.wav', 'spk_id01228_sep_141.wav', 'spk_id05594_sep_76.wav', 'spk_id05999_sep_427.wav', 'spk_id04656_sep_323.wav', 'spk_id01567_sep_287.wav', 'spk_id02548_sep_52.wav', 'spk_id04094_sep_413.wav', 'spk_id02725_sep_421.wav', 'spk_id00812_sep_73.wav', 'spk_id02745_sep_495.wav', 'spk_id03862_sep_82.wav', 'spk_id01224_sep_327.wav', 'spk_id01509_sep_256.wav', 'spk_id05124_sep_122.wav', 'spk_id07312_sep_414.wav', 'spk_id03969_sep_151.wav', 'spk_id01298_sep_440.wav', 'spk_id01333_sep_145.wav', 'spk_id05202_sep_126.wav', 'spk_id05816_sep_273.wav', 'spk_id07414_sep_334.wav', 'spk_id03969_sep_159.wav', 'spk_id06692_sep_170.wav', 'spk_id01460_sep_80.wav', 'spk_id00562_sep_248.wav', 'spk_id00154_sep_381.wav', 'spk_id02745_sep_322.wav', 'spk_id05459_sep_107.wav', 'spk_id01989_sep_135.wav', 'spk_id00866_sep_469.wav', 'spk_id06913_sep_33.wav', 'spk_id01989_sep_436.wav', 'spk_id05850_sep_343.wav', 'spk_id00812_sep_135.wav', 'spk_id02019_sep_340.wav', 'spk_id04030_sep_165.wav', 'spk_id01228_sep_208.wav', 'spk_id07426_sep_345.wav', 'spk_id05202_sep_100.wav', 'spk_id06816_sep_25.wav', 'spk_id02685_sep_462.wav', 'spk_id00817_sep_406.wav', 'spk_id05015_sep_171.wav', 'spk_id00562_sep_303.wav', 'spk_id02725_sep_56.wav', 'spk_id03524_sep_123.wav', 'spk_id05124_sep_305.wav', 'spk_id00017_sep_16.wav', 'spk_id01509_sep_431.wav', 'spk_id06692_sep_371.wav', 'spk_id03862_sep_301.wav', 'spk_id04006_sep_173.wav', 'spk_id06209_sep_320.wav', 'spk_id02086_sep_67.wav', 'spk_id03969_sep_469.wav', 'spk_id00419_sep_309.wav', 'spk_id00812_sep_266.wav', 'spk_id06209_sep_309.wav', 'spk_id01224_sep_6.wav', 'spk_id00419_sep_368.wav', 'spk_id00419_sep_104.wav', 'spk_id04232_sep_346.wav', 'spk_id00817_sep_379.wav', 'spk_id04950_sep_83.wav', 'spk_id00419_sep_391.wav', 'spk_id02057_sep_416.wav', 'spk_id01228_sep_393.wav', 'spk_id03677_sep_483.wav', 'spk_id02086_sep_202.wav', 'spk_id02577_sep_335.wav', 'spk_id02086_sep_293.wav', 'spk_id04570_sep_459.wav', 'spk_id01333_sep_235.wav', 'spk_id00812_sep_373.wav', 'spk_id06692_sep_88.wav', 'spk_id03839_sep_233.wav', 'spk_id03981_sep_369.wav', 'spk_id04119_sep_425.wav', 'spk_id01224_sep_205.wav', 'spk_id02725_sep_35.wav', 'spk_id05124_sep_324.wav', 'spk_id01593_sep_275.wav', 'spk_id03839_sep_284.wav', 'spk_id01000_sep_398.wav', 'spk_id05850_sep_443.wav', 'spk_id03978_sep_40.wav', 'spk_id01892_sep_91.wav', 'spk_id05850_sep_472.wav', 'spk_id01298_sep_219.wav', 'spk_id01593_sep_236.wav', 'spk_id05594_sep_232.wav', 'spk_id01892_sep_191.wav', 'spk_id01892_sep_298.wav', 'spk_id02086_sep_126.wav', 'spk_id00562_sep_291.wav', 'spk_id04253_sep_45.wav', 'spk_id06692_sep_193.wav', 'spk_id02019_sep_105.wav', 'spk_id05124_sep_203.wav', 'spk_id02086_sep_419.wav', 'spk_id06913_sep_223.wav', 'spk_id07414_sep_109.wav', 'spk_id05124_sep_439.wav', 'spk_id00866_sep_321.wav', 'spk_id04950_sep_110.wav', 'spk_id04295_sep_394.wav', 'spk_id03524_sep_47.wav', 'spk_id03524_sep_375.wav', 'spk_id07426_sep_308.wav', 'spk_id06692_sep_231.wav', 'spk_id01066_sep_18.wav', 'spk_id04030_sep_471.wav', 'spk_id00812_sep_90.wav', 'spk_id06104_sep_492.wav', 'spk_id06310_sep_21.wav', 'spk_id02445_sep_434.wav', 'spk_id00866_sep_329.wav', 'spk_id01224_sep_254.wav', 'spk_id02019_sep_354.wav', 'spk_id02577_sep_226.wav', 'spk_id02019_sep_491.wav', 'spk_id02465_sep_250.wav', 'spk_id06484_sep_146.wav', 'spk_id04006_sep_49.wav', 'spk_id01228_sep_359.wav', 'spk_id00562_sep_310.wav', 'spk_id05714_sep_390.wav', 'spk_id05055_sep_467.wav', 'spk_id02317_sep_408.wav', 'spk_id04478_sep_144.wav', 'spk_id04094_sep_114.wav', 'spk_id05999_sep_389.wav', 'spk_id03981_sep_155.wav', 'spk_id01333_sep_313.wav', 'spk_id04570_sep_484.wav', 'spk_id01228_sep_195.wav', 'spk_id02019_sep_95.wav', 'spk_id02685_sep_228.wav', 'spk_id04276_sep_271.wav', 'spk_id01041_sep_277.wav', 'spk_id02286_sep_185.wav', 'spk_id03178_sep_56.wav', 'spk_id04119_sep_370.wav', 'spk_id00866_sep_403.wav', 'spk_id03978_sep_441.wav', 'spk_id03524_sep_470.wav', 'spk_id03030_sep_289.wav', 'spk_id07312_sep_102.wav', 'spk_id04366_sep_460.wav', 'spk_id05654_sep_270.wav', 'spk_id04006_sep_479.wav', 'spk_id01460_sep_461.wav', 'spk_id01593_sep_227.wav', 'spk_id07426_sep_445.wav', 'spk_id00926_sep_229.wav', 'spk_id06484_sep_70.wav', 'spk_id07396_sep_110.wav', 'spk_id07354_sep_412.wav', 'spk_id02465_sep_257.wav', 'spk_id04006_sep_172.wav', 'spk_id04656_sep_237.wav', 'spk_id01509_sep_192.wav', 'spk_id00812_sep_50.wav', 'spk_id05850_sep_475.wav', 'spk_id02548_sep_162.wav', 'spk_id03789_sep_125.wav', 'spk_id00081_sep_394.wav', 'spk_id06104_sep_437.wav', 'spk_id04006_sep_381.wav', 'spk_id04570_sep_2.wav', 'spk_id06484_sep_480.wav', 'spk_id05459_sep_426.wav', 'spk_id01567_sep_357.wav', 'spk_id04232_sep_69.wav', 'spk_id01892_sep_258.wav', 'spk_id01298_sep_156.wav', 'spk_id04366_sep_411.wav', 'spk_id04094_sep_363.wav', 'spk_id01066_sep_54.wav', 'spk_id02445_sep_10.wav', 'spk_id06913_sep_16.wav', 'spk_id01567_sep_30.wav', 'spk_id03862_sep_160.wav', 'spk_id04570_sep_220.wav', 'spk_id01460_sep_351.wav', 'spk_id01106_sep_330.wav', 'spk_id03980_sep_169.wav', 'spk_id00154_sep_374.wav', 'spk_id01822_sep_300.wav', 'spk_id05999_sep_299.wav', 'spk_id04570_sep_249.wav', 'spk_id02181_sep_33.wav', 'spk_id03041_sep_217.wav', 'spk_id01106_sep_247.wav', 'spk_id05816_sep_314.wav', 'spk_id03178_sep_42.wav', 'spk_id07354_sep_292.wav', 'spk_id01618_sep_143.wav', 'spk_id04570_sep_67.wav', 'spk_id01000_sep_98.wav', 'spk_id01541_sep_93.wav', 'spk_id05850_sep_383.wav', 'spk_id05850_sep_444.wav', 'spk_id01298_sep_477.wav', 'spk_id01298_sep_168.wav', 'spk_id02057_sep_293.wav', 'spk_id01333_sep_243.wav', 'spk_id00562_sep_162.wav', 'spk_id04478_sep_353.wav', 'spk_id01298_sep_480.wav', 'spk_id03789_sep_59.wav', 'spk_id01567_sep_179.wav', 'spk_id01041_sep_121.wav', 'spk_id05202_sep_81.wav', 'spk_id01892_sep_154.wav', 'spk_id07354_sep_490.wav', 'spk_id03677_sep_456.wav', 'spk_id03524_sep_166.wav', 'spk_id01892_sep_417.wav', 'spk_id01593_sep_194.wav', 'spk_id06310_sep_466.wav', 'spk_id04276_sep_134.wav', 'spk_id04570_sep_313.wav', 'spk_id06913_sep_418.wav', 'spk_id03030_sep_261.wav', 'spk_id02576_sep_95.wav', 'spk_id07354_sep_262.wav', 'spk_id04656_sep_76.wav', 'spk_id03978_sep_424.wav', 'spk_id00562_sep_119.wav', 'spk_id06209_sep_47.wav', 'spk_id02086_sep_359.wav', 'spk_id04656_sep_282.wav', 'spk_id03980_sep_357.wav', 'spk_id03980_sep_189.wav', 'spk_id02548_sep_87.wav', 'spk_id02465_sep_470.wav', 'spk_id01989_sep_152.wav', 'spk_id03041_sep_221.wav', 'spk_id02548_sep_78.wav', 'spk_id02548_sep_410.wav', 'spk_id00866_sep_485.wav', 'spk_id02317_sep_12.wav', 'spk_id01000_sep_197.wav', 'spk_id02542_sep_190.wav', 'spk_id00419_sep_477.wav', 'spk_id01333_sep_45.wav', 'spk_id05055_sep_478.wav', 'spk_id00017_sep_259.wav', 'spk_id06811_sep_433.wav', 'spk_id04536_sep_428.wav', 'spk_id00866_sep_105.wav', 'spk_id04295_sep_112.wav', 'spk_id01437_sep_6.wav', 'spk_id00154_sep_264.wav', 'spk_id02745_sep_101.wav', 'spk_id03041_sep_297.wav', 'spk_id04536_sep_375.wav', 'spk_id03839_sep_242.wav', 'spk_id06816_sep_227.wav', 'spk_id06104_sep_132.wav', 'spk_id05714_sep_127.wav', 'spk_id03030_sep_188.wav', 'spk_id05850_sep_24.wav', 'spk_id01437_sep_177.wav', 'spk_id04119_sep_303.wav', 'spk_id01228_sep_187.wav', 'spk_id04657_sep_150.wav', 'spk_id04006_sep_388.wav', 'spk_id05654_sep_184.wav', 'spk_id04276_sep_215.wav', 'spk_id04366_sep_331.wav', 'spk_id02725_sep_333.wav', 'spk_id02745_sep_235.wav', 'spk_id02548_sep_349.wav', 'spk_id01041_sep_429.wav', 'spk_id06692_sep_5.wav', 'spk_id02445_sep_64.wav', 'spk_id02317_sep_256.wav', 'spk_id07312_sep_79.wav', 'spk_id00419_sep_448.wav', 'spk_id00154_sep_421.wav', 'spk_id01989_sep_165.wav', 'spk_id04030_sep_457.wav', 'spk_id01224_sep_224.wav', 'spk_id06484_sep_129.wav', 'spk_id03969_sep_127.wav', 'spk_id04094_sep_116.wav', 'spk_id00562_sep_21.wav', 'spk_id03978_sep_29.wav', 'spk_id05055_sep_255.wav', 'spk_id02019_sep_264.wav', 'spk_id06209_sep_384.wav', 'spk_id04570_sep_367.wav', 'spk_id03347_sep_177.wav', 'spk_id03041_sep_364.wav', 'spk_id05654_sep_419.wav', 'spk_id03839_sep_392.wav', 'spk_id02057_sep_163.wav', 'spk_id01228_sep_96.wav', 'spk_id06104_sep_34.wav', 'spk_id04253_sep_209.wav', 'spk_id00817_sep_318.wav', 'spk_id05714_sep_272.wav', 'spk_id00061_sep_434.wav', 'spk_id02286_sep_22.wav', 'spk_id00812_sep_14.wav', 'spk_id02181_sep_344.wav', 'spk_id01437_sep_36.wav', 'spk_id02745_sep_362.wav', 'spk_id02576_sep_299.wav', 'spk_id04656_sep_71.wav', 'spk_id03969_sep_75.wav', 'spk_id01892_sep_196.wav', 'spk_id05594_sep_414.wav', 'spk_id04627_sep_403.wav', 'spk_id07312_sep_153.wav', 'spk_id01228_sep_94.wav', 'spk_id01593_sep_210.wav', 'spk_id01298_sep_139.wav', 'spk_id00866_sep_415.wav', 'spk_id02086_sep_307.wav', 'spk_id01460_sep_46.wav', 'spk_id02576_sep_147.wav', 'spk_id04119_sep_143.wav', 'spk_id01333_sep_327.wav', 'spk_id02685_sep_8.wav', 'spk_id04366_sep_462.wav', 'spk_id07396_sep_273.wav', 'spk_id00812_sep_496.wav', 'spk_id06484_sep_183.wav', 'spk_id01541_sep_398.wav', 'spk_id04478_sep_486.wav', 'spk_id00562_sep_326.wav', 'spk_id05202_sep_253.wav', 'spk_id03382_sep_321.wav', 'spk_id04276_sep_84.wav', 'spk_id04030_sep_119.wav', 'spk_id01298_sep_409.wav', 'spk_id02086_sep_34.wav', 'spk_id06692_sep_389.wav', 'spk_id04627_sep_429.wav', 'spk_id04478_sep_234.wav', 'spk_id03789_sep_240.wav', 'spk_id01892_sep_65.wav', 'spk_id04295_sep_437.wav', 'spk_id04478_sep_351.wav', 'spk_id03524_sep_285.wav', 'spk_id07414_sep_350.wav', 'spk_id01333_sep_479.wav', 'spk_id05654_sep_376.wav', 'spk_id04119_sep_231.wav', 'spk_id03969_sep_290.wav', 'spk_id05124_sep_63.wav', 'spk_id02542_sep_494.wav', 'spk_id00866_sep_457.wav', 'spk_id01437_sep_366.wav', 'spk_id04478_sep_58.wav', 'spk_id01333_sep_36.wav', 'spk_id07354_sep_268.wav', 'spk_id01333_sep_341.wav', 'spk_id04536_sep_48.wav', 'spk_id04006_sep_209.wav', 'spk_id05015_sep_204.wav', 'spk_id03178_sep_373.wav', 'spk_id03969_sep_70.wav', 'spk_id02181_sep_65.wav', 'spk_id01618_sep_355.wav', 'spk_id03677_sep_333.wav', 'spk_id01460_sep_453.wav', 'spk_id03839_sep_499.wav', 'spk_id05654_sep_161.wav', 'spk_id01618_sep_108.wav', 'spk_id02576_sep_286.wav', 'spk_id06104_sep_404.wav', 'spk_id01224_sep_456.wav', 'spk_id06310_sep_243.wav', 'spk_id01041_sep_124.wav', 'spk_id04232_sep_410.wav', 'spk_id01541_sep_433.wav', 'spk_id05459_sep_328.wav', 'spk_id02181_sep_153.wav', 'spk_id01541_sep_30.wav', 'spk_id02542_sep_169.wav', 'spk_id05202_sep_482.wav', 'spk_id03789_sep_89.wav', 'spk_id01593_sep_431.wav', 'spk_id01041_sep_32.wav', 'spk_id05124_sep_130.wav', 'spk_id04536_sep_216.wav', 'spk_id00866_sep_382.wav', 'spk_id00817_sep_498.wav', 'spk_id02465_sep_116.wav', 'spk_id00926_sep_7.wav', 'spk_id05999_sep_328.wav', 'spk_id04366_sep_358.wav', 'spk_id04950_sep_156.wav', 'spk_id06484_sep_492.wav', 'spk_id05124_sep_385.wav', 'spk_id01298_sep_72.wav', 'spk_id05124_sep_322.wav', 'spk_id06692_sep_201.wav', 'spk_id02725_sep_188.wav', 'spk_id02317_sep_447.wav', 'spk_id02465_sep_465.wav', 'spk_id00817_sep_402.wav', 'spk_id03382_sep_302.wav', 'spk_id04657_sep_277.wav', 'spk_id03969_sep_471.wav', 'spk_id02019_sep_259.wav', 'spk_id01541_sep_238.wav', 'spk_id03041_sep_339.wav', 'spk_id00866_sep_286.wav', 'spk_id00061_sep_365.wav', 'spk_id06209_sep_411.wav', 'spk_id06816_sep_210.wav', 'spk_id04627_sep_207.wav', 'spk_id03789_sep_449.wav', 'spk_id01822_sep_211.wav', 'spk_id05055_sep_317.wav', 'spk_id03980_sep_37.wav', 'spk_id04030_sep_440.wav', 'spk_id03524_sep_288.wav', 'spk_id00817_sep_494.wav', 'spk_id01437_sep_121.wav', 'spk_id03178_sep_377.wav', 'spk_id02745_sep_427.wav', 'spk_id03839_sep_74.wav', 'spk_id04950_sep_348.wav', 'spk_id00866_sep_451.wav', 'spk_id04119_sep_378.wav', 'spk_id04656_sep_426.wav', 'spk_id01822_sep_111.wav', 'spk_id04627_sep_454.wav', 'spk_id05202_sep_281.wav', 'spk_id00081_sep_311.wav', 'spk_id01989_sep_295.wav', 'spk_id00562_sep_108.wav', 'spk_id04657_sep_366.wav', 'spk_id05202_sep_212.wav', 'spk_id02548_sep_179.wav', 'spk_id05714_sep_276.wav', 'spk_id01437_sep_489.wav', 'spk_id04656_sep_125.wav', 'spk_id01106_sep_182.wav', 'spk_id05714_sep_222.wav', 'spk_id00081_sep_461.wav', 'spk_id03030_sep_474.wav', 'spk_id02086_sep_106.wav', 'spk_id03041_sep_86.wav', 'spk_id04862_sep_204.wav', 'spk_id01224_sep_129.wav', 'spk_id01822_sep_446.wav', 'spk_id02548_sep_442.wav', 'spk_id01066_sep_51.wav', 'spk_id01822_sep_222.wav', 'spk_id02577_sep_452.wav', 'spk_id01989_sep_288.wav', 'spk_id04478_sep_199.wav', 'spk_id03789_sep_481.wav', 'spk_id01892_sep_199.wav', 'spk_id05999_sep_276.wav', 'spk_id05176_sep_263.wav', 'spk_id03347_sep_420.wav', 'spk_id03524_sep_238.wav', 'spk_id05850_sep_438.wav', 'spk_id04950_sep_140.wav', 'spk_id01000_sep_376.wav', 'spk_id02317_sep_291.wav', 'spk_id01989_sep_298.wav', 'spk_id00866_sep_40.wav', 'spk_id02317_sep_202.wav', 'spk_id01041_sep_0.wav', 'spk_id01541_sep_244.wav', 'spk_id03030_sep_68.wav', 'spk_id03030_sep_386.wav', 'spk_id04950_sep_487.wav', 'spk_id02086_sep_245.wav', 'spk_id02576_sep_369.wav', 'spk_id05124_sep_66.wav', 'spk_id06104_sep_246.wav', 'spk_id03178_sep_407.wav', 'spk_id02548_sep_383.wav', 'spk_id05176_sep_13.wav', 'spk_id04478_sep_223.wav', 'spk_id02317_sep_350.wav', 'spk_id04006_sep_395.wav', 'spk_id00817_sep_57.wav', 'spk_id05714_sep_285.wav', 'spk_id05654_sep_329.wav', 'spk_id00817_sep_424.wav', 'spk_id05816_sep_387.wav', 'spk_id02465_sep_175.wav', 'spk_id03980_sep_362.wav', 'spk_id02576_sep_450.wav', 'spk_id04366_sep_150.wav', 'spk_id07426_sep_19.wav', 'spk_id00812_sep_117.wav', 'spk_id02019_sep_214.wav', 'spk_id03524_sep_377.wav', 'spk_id05176_sep_213.wav', 'spk_id06913_sep_59.wav', 'spk_id04276_sep_272.wav', 'spk_id06811_sep_489.wav', 'spk_id02445_sep_465.wav', 'spk_id07426_sep_463.wav', 'spk_id04536_sep_229.wav', 'spk_id07312_sep_115.wav', 'spk_id06104_sep_211.wav', 'spk_id01000_sep_287.wav', 'spk_id04862_sep_304.wav', 'spk_id03347_sep_372.wav', 'spk_id05816_sep_464.wav', 'spk_id05850_sep_247.wav', 'spk_id02548_sep_164.wav', 'spk_id04627_sep_230.wav', 'spk_id06913_sep_262.wav', 'spk_id04253_sep_294.wav', 'spk_id01593_sep_186.wav', 'spk_id03677_sep_281.wav', 'spk_id07312_sep_24.wav', 'spk_id01000_sep_468.wav', 'spk_id04295_sep_237.wav', 'spk_id02465_sep_220.wav', 'spk_id00866_sep_142.wav', 'spk_id07396_sep_78.wav', 'spk_id01224_sep_131.wav', 'spk_id02286_sep_197.wav', 'spk_id02317_sep_104.wav', 'spk_id01892_sep_445.wav', 'spk_id01228_sep_163.wav', 'spk_id01822_sep_80.wav', 'spk_id02181_sep_72.wav', 'spk_id01460_sep_92.wav', 'spk_id06811_sep_372.wav', 'spk_id01437_sep_386.wav', 'spk_id01041_sep_134.wav', 'spk_id00154_sep_258.wav', 'spk_id00081_sep_283.wav', 'spk_id00061_sep_221.wav', 'spk_id00926_sep_69.wav', 'spk_id01618_sep_85.wav', 'spk_id03041_sep_113.wav', 'spk_id07312_sep_296.wav', 'spk_id04006_sep_71.wav', 'spk_id01567_sep_331.wav', 'spk_id01106_sep_31.wav', 'spk_id06484_sep_174.wav', 'spk_id00812_sep_9.wav', 'spk_id05594_sep_405.wav', 'spk_id03862_sep_176.wav', 'spk_id01298_sep_183.wav', 'spk_id04536_sep_68.wav', 'spk_id03789_sep_447.wav', 'spk_id01541_sep_94.wav', 'spk_id02057_sep_280.wav', 'spk_id01333_sep_425.wav', 'spk_id04276_sep_472.wav', 'spk_id01298_sep_8.wav', 'spk_id05124_sep_319.wav', 'spk_id03347_sep_58.wav', 'spk_id05015_sep_241.wav', 'spk_id00017_sep_269.wav', 'spk_id01541_sep_147.wav', 'spk_id05124_sep_248.wav', 'spk_id04006_sep_39.wav', 'spk_id05176_sep_178.wav', 'spk_id03178_sep_409.wav', 'spk_id02317_sep_268.wav', 'spk_id04366_sep_481.wav', 'spk_id01509_sep_260.wav', 'spk_id03980_sep_168.wav', 'spk_id02181_sep_145.wav', 'spk_id04536_sep_399.wav', 'spk_id03981_sep_397.wav', 'spk_id02181_sep_87.wav', 'spk_id00419_sep_61.wav', 'spk_id03347_sep_418.wav', 'spk_id04862_sep_334.wav', 'spk_id03524_sep_224.wav', 'spk_id03041_sep_46.wav', 'spk_id03347_sep_422.wav', 'spk_id00562_sep_93.wav', 'spk_id05124_sep_79.wav', 'spk_id03862_sep_244.wav', 'spk_id06913_sep_50.wav', 'spk_id03030_sep_467.wav', 'spk_id01822_sep_97.wav', 'spk_id03980_sep_336.wav', 'spk_id03980_sep_19.wav', 'spk_id04657_sep_483.wav', 'spk_id02465_sep_124.wav', 'spk_id06913_sep_144.wav', 'spk_id04276_sep_233.wav', 'spk_id01224_sep_217.wav']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/kaggle/working/separated_audio\"\n",
    "print(os.listdir(folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T18:28:45.043283Z",
     "iopub.status.busy": "2025-04-02T18:28:45.042924Z",
     "iopub.status.idle": "2025-04-02T18:28:57.957530Z",
     "shell.execute_reply": "2025-04-02T18:28:57.956766Z",
     "shell.execute_reply.started": "2025-04-02T18:28:45.043255Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/my_output.zip'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive('/kaggle/working/my_output', 'zip', '/kaggle/working/separated_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:25.504154Z",
     "iopub.status.busy": "2025-04-02T21:23:25.503869Z",
     "iopub.status.idle": "2025-04-02T21:23:25.509647Z",
     "shell.execute_reply": "2025-04-02T21:23:25.508915Z",
     "shell.execute_reply.started": "2025-04-02T21:23:25.504131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/kaggle/working/separated_audio\" \n",
    "files_and_dirs = os.listdir(folder_path)\n",
    "print(len(files_and_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:30.013946Z",
     "iopub.status.busy": "2025-04-02T21:23:30.013581Z",
     "iopub.status.idle": "2025-04-02T21:23:30.019295Z",
     "shell.execute_reply": "2025-04-02T21:23:30.018425Z",
     "shell.execute_reply.started": "2025-04-02T21:23:30.013917Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_embedding(model, processor, waveform, sample_rate=TARGET_SAMPLE_RATE_16):\n",
    "    input_values = processor(waveform.squeeze().numpy(), sampling_rate=sample_rate, return_tensors=\"pt\").input_values\n",
    "    input_values = input_values.to(next(model.parameters()).device)\n",
    "    with torch.no_grad():\n",
    "        if hasattr(model, \"extract_embeddings\"):\n",
    "            embedding = model.extract_embeddings(input_values)\n",
    "        else:\n",
    "            outputs = model(input_values)\n",
    "            embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embedding.squeeze()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:23:32.127306Z",
     "iopub.status.busy": "2025-04-02T21:23:32.127014Z",
     "iopub.status.idle": "2025-04-02T21:23:32.131695Z",
     "shell.execute_reply": "2025-04-02T21:23:32.130889Z",
     "shell.execute_reply.started": "2025-04-02T21:23:32.127282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def identify_speaker(embedding, enrollment_embeddings):\n",
    "    best_id = None\n",
    "    best_sim = -float('inf')\n",
    "    for spk, enroll_emb in enrollment_embeddings.items():\n",
    "        sim = torch.cosine_similarity(embedding, enroll_emb, dim=0).item()\n",
    "        if sim > best_sim:\n",
    "            best_sim = sim\n",
    "            best_id = spk\n",
    "    return best_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:24:14.798919Z",
     "iopub.status.busy": "2025-04-02T21:24:14.798577Z",
     "iopub.status.idle": "2025-04-02T21:24:14.803251Z",
     "shell.execute_reply": "2025-04-02T21:24:14.802412Z",
     "shell.execute_reply.started": "2025-04-02T21:24:14.798888Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total speakers: 118\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total speakers: {len(all_speakers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T21:17:18.667997Z",
     "iopub.status.busy": "2025-04-01T21:17:18.667667Z",
     "iopub.status.idle": "2025-04-01T21:17:18.671688Z",
     "shell.execute_reply": "2025-04-01T21:17:18.670645Z",
     "shell.execute_reply.started": "2025-04-01T21:17:18.667972Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "new_test_ids = all_speakers[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:01.045945Z",
     "iopub.status.busy": "2025-04-02T21:25:01.045599Z",
     "iopub.status.idle": "2025-04-02T21:25:01.049586Z",
     "shell.execute_reply": "2025-04-02T21:25:01.048743Z",
     "shell.execute_reply.started": "2025-04-02T21:25:01.045915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor, WavLMModel\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:02.617964Z",
     "iopub.status.busy": "2025-04-02T21:25:02.617645Z",
     "iopub.status.idle": "2025-04-02T21:25:02.623253Z",
     "shell.execute_reply": "2025-04-02T21:25:02.622430Z",
     "shell.execute_reply.started": "2025-04-02T21:25:02.617936Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:04.389467Z",
     "iopub.status.busy": "2025-04-02T21:25:04.389169Z",
     "iopub.status.idle": "2025-04-02T21:25:05.103531Z",
     "shell.execute_reply": "2025-04-02T21:25:05.102212Z",
     "shell.execute_reply.started": "2025-04-02T21:25:04.389445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = WavLMModel.from_pretrained(\"microsoft/wavlm-base-plus\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:07.861354Z",
     "iopub.status.busy": "2025-04-02T21:25:07.861011Z",
     "iopub.status.idle": "2025-04-02T21:25:07.866205Z",
     "shell.execute_reply": "2025-04-02T21:25:07.865386Z",
     "shell.execute_reply.started": "2025-04-02T21:25:07.861318Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:09.461443Z",
     "iopub.status.busy": "2025-04-02T21:25:09.461109Z",
     "iopub.status.idle": "2025-04-02T21:25:09.468454Z",
     "shell.execute_reply": "2025-04-02T21:25:09.467521Z",
     "shell.execute_reply.started": "2025-04-02T21:25:09.461403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(torch.clamp(1.0 - torch.pow(cosine, 2), min=1e-6))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        one_hot = torch.zeros(cosine.size(), device=input.device)\n",
    "        one_hot.scatter_(1, label.view(-1, 1), 1)\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:11.198467Z",
     "iopub.status.busy": "2025-04-02T21:25:11.198140Z",
     "iopub.status.idle": "2025-04-02T21:25:11.204224Z",
     "shell.execute_reply": "2025-04-02T21:25:11.203369Z",
     "shell.execute_reply.started": "2025-04-02T21:25:11.198430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, r=4, alpha=16.0, dropout=0.1):\n",
    "        super(LoRALinear, self).__init__()\n",
    "        self.r = r\n",
    "        if r > 0:\n",
    "            self.lora_A = nn.Linear(in_features, r, bias=False)\n",
    "            self.lora_B = nn.Linear(r, out_features, bias=False)\n",
    "            self.scaling = alpha / r\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.lora_A = None\n",
    "            self.lora_B = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.r > 0:\n",
    "            return self.lora_B(self.dropout(self.lora_A(x))) * self.scaling\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:12.628026Z",
     "iopub.status.busy": "2025-04-02T21:25:12.627677Z",
     "iopub.status.idle": "2025-04-02T21:25:12.634030Z",
     "shell.execute_reply": "2025-04-02T21:25:12.633191Z",
     "shell.execute_reply.started": "2025-04-02T21:25:12.627998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FineTuneModel(nn.Module):\n",
    "    def __init__(self, pretrained_model, embedding_dim, num_classes, lora_r=4, lora_alpha=16):\n",
    "        super(FineTuneModel, self).__init__()\n",
    "        self.pretrained = pretrained_model\n",
    "        for param in self.pretrained.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lora = LoRALinear(embedding_dim, embedding_dim, r=lora_r, alpha=lora_alpha)\n",
    "        self.arcface = ArcMarginProduct(embedding_dim, num_classes)\n",
    "    \n",
    "    def forward(self, input_values, labels):\n",
    "        outputs = self.pretrained(input_values)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        adapted_embeddings = embeddings + self.lora(embeddings)\n",
    "        logits = self.arcface(adapted_embeddings, labels)\n",
    "        return logits, adapted_embeddings\n",
    "    \n",
    "  \n",
    "    def extract_embeddings(self, input_values):\n",
    "        outputs = self.pretrained(input_values)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        adapted_embeddings = embeddings + self.lora(embeddings)\n",
    "        return adapted_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:15.266728Z",
     "iopub.status.busy": "2025-04-02T21:25:15.266271Z",
     "iopub.status.idle": "2025-04-02T21:25:15.270542Z",
     "shell.execute_reply": "2025-04-02T21:25:15.269725Z",
     "shell.execute_reply.started": "2025-04-02T21:25:15.266682Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:22.893417Z",
     "iopub.status.busy": "2025-04-02T21:25:22.893134Z",
     "iopub.status.idle": "2025-04-02T21:25:22.906407Z",
     "shell.execute_reply": "2025-04-02T21:25:22.905576Z",
     "shell.execute_reply.started": "2025-04-02T21:25:22.893393Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneModel(\n",
       "  (pretrained): WavLMModel(\n",
       "    (feature_extractor): WavLMFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): WavLMGroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x WavLMNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x WavLMNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): WavLMFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): WavLMEncoder(\n",
       "      (pos_conv_embed): WavLMPositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): WavLMSamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): WavLMEncoderLayer(\n",
       "          (attention): WavLMAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (rel_attn_embed): Embedding(320, 12)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): WavLMFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1-11): 11 x WavLMEncoderLayer(\n",
       "          (attention): WavLMAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): WavLMFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lora): LoRALinear(\n",
       "    (lora_A): Linear(in_features=768, out_features=4, bias=False)\n",
       "    (lora_B): Linear(in_features=4, out_features=768, bias=False)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (arcface): ArcMarginProduct()\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = pretrained_model.config.hidden_size  \n",
    "num_classes = len(test_ids)         \n",
    "finetune_model = FineTuneModel(pretrained_model, embedding_dim, num_classes, lora_r=4, lora_alpha=16)\n",
    "finetune_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:26.555459Z",
     "iopub.status.busy": "2025-04-02T21:25:26.555177Z",
     "iopub.status.idle": "2025-04-02T21:25:26.829021Z",
     "shell.execute_reply": "2025-04-02T21:25:26.827921Z",
     "shell.execute_reply.started": "2025-04-02T21:25:26.555437Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-108-77b0505534ec>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  finetune_model.load_state_dict(torch.load(\"/kaggle/input/finetuned-model/best_finetune_model_epoch10.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_model.load_state_dict(torch.load(\"/kaggle/input/finetuned-model/best_finetune_model_epoch10.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:29.308596Z",
     "iopub.status.busy": "2025-04-02T21:25:29.308288Z",
     "iopub.status.idle": "2025-04-02T21:25:29.425328Z",
     "shell.execute_reply": "2025-04-02T21:25:29.424691Z",
     "shell.execute_reply.started": "2025-04-02T21:25:29.308570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processor = Wav2Vec2FeatureExtractor.from_pretrained(\"microsoft/wavlm-base-plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T20:51:55.317575Z",
     "iopub.status.busy": "2025-04-02T20:51:55.317288Z",
     "iopub.status.idle": "2025-04-02T20:51:55.328465Z",
     "shell.execute_reply": "2025-04-02T20:51:55.327613Z",
     "shell.execute_reply.started": "2025-04-02T20:51:55.317552Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WavLMModel(\n",
       "  (feature_extractor): WavLMFeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): WavLMGroupNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1-4): 4 x WavLMNoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x WavLMNoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): WavLMFeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): WavLMEncoder(\n",
       "    (pos_conv_embed): WavLMPositionalConvEmbedding(\n",
       "      (conv): ParametrizedConv1d(\n",
       "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _WeightNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (padding): WavLMSamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): WavLMEncoderLayer(\n",
       "        (attention): WavLMAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          (rel_attn_embed): Embedding(320, 12)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): WavLMFeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1-11): 11 x WavLMEncoderLayer(\n",
       "        (attention): WavLMAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): WavLMFeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pretrained_model.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:33.128659Z",
     "iopub.status.busy": "2025-04-02T21:25:33.128336Z",
     "iopub.status.idle": "2025-04-02T21:25:33.140718Z",
     "shell.execute_reply": "2025-04-02T21:25:33.139861Z",
     "shell.execute_reply.started": "2025-04-02T21:25:33.128629Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuneModel(\n",
       "  (pretrained): WavLMModel(\n",
       "    (feature_extractor): WavLMFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): WavLMGroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x WavLMNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x WavLMNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): WavLMFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): WavLMEncoder(\n",
       "      (pos_conv_embed): WavLMPositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): WavLMSamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): WavLMEncoderLayer(\n",
       "          (attention): WavLMAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "            (rel_attn_embed): Embedding(320, 12)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): WavLMFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1-11): 11 x WavLMEncoderLayer(\n",
       "          (attention): WavLMAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (gru_rel_pos_linear): Linear(in_features=64, out_features=8, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): WavLMFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lora): LoRALinear(\n",
       "    (lora_A): Linear(in_features=768, out_features=4, bias=False)\n",
       "    (lora_B): Linear(in_features=4, out_features=768, bias=False)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (arcface): ArcMarginProduct()\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:39.679214Z",
     "iopub.status.busy": "2025-04-02T21:25:39.678909Z",
     "iopub.status.idle": "2025-04-02T21:25:39.685186Z",
     "shell.execute_reply": "2025-04-02T21:25:39.684503Z",
     "shell.execute_reply.started": "2025-04-02T21:25:39.679191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "enrollment_embeddings_pretrained = {}\n",
    "enrollment_embeddings_finetuned = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:56.442380Z",
     "iopub.status.busy": "2025-04-02T21:25:56.442092Z",
     "iopub.status.idle": "2025-04-02T21:25:56.447359Z",
     "shell.execute_reply": "2025-04-02T21:25:56.446499Z",
     "shell.execute_reply.started": "2025-04-02T21:25:56.442357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "resample_to_16k = T.Resample(orig_freq=8000, new_freq=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:25:58.131816Z",
     "iopub.status.busy": "2025-04-02T21:25:58.131523Z",
     "iopub.status.idle": "2025-04-02T21:26:04.174834Z",
     "shell.execute_reply": "2025-04-02T21:26:04.174184Z",
     "shell.execute_reply.started": "2025-04-02T21:25:58.131792Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for spk in test_ids:\n",
    "    if spk in speaker_dict:\n",
    "        enrollment_file = speaker_dict[spk][0]  \n",
    "        waveform = load_audio_file_16(enrollment_file)  \n",
    "        emb_pre = extract_embedding(pretrained_model, processor, waveform, TARGET_SAMPLE_RATE_16)\n",
    "        emb_ft = extract_embedding(finetune_model, processor, waveform, TARGET_SAMPLE_RATE_16)\n",
    "        enrollment_embeddings_pretrained[spk] = emb_pre\n",
    "        enrollment_embeddings_finetuned[spk] = emb_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:26:07.256681Z",
     "iopub.status.busy": "2025-04-02T21:26:07.256388Z",
     "iopub.status.idle": "2025-04-02T21:26:07.261809Z",
     "shell.execute_reply": "2025-04-02T21:26:07.261007Z",
     "shell.execute_reply.started": "2025-04-02T21:26:07.256658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enrollment_embeddings_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:26:40.835452Z",
     "iopub.status.busy": "2025-04-02T21:26:40.835127Z",
     "iopub.status.idle": "2025-04-02T21:26:40.839112Z",
     "shell.execute_reply": "2025-04-02T21:26:40.838296Z",
     "shell.execute_reply.started": "2025-04-02T21:26:40.835412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "correct_pretrained = 0\n",
    "correct_finetuned = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T21:27:02.640672Z",
     "iopub.status.busy": "2025-04-02T21:27:02.640390Z",
     "iopub.status.idle": "2025-04-02T21:28:47.061603Z",
     "shell.execute_reply": "2025-04-02T21:28:47.060902Z",
     "shell.execute_reply.started": "2025-04-02T21:27:02.640649Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Identifying speakers: 100%|██████████| 500/500 [01:44<00:00,  4.79it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, (mixture, _, true_speakers) in enumerate(tqdm(test_mixtures, desc=\"Identifying speakers\")):\n",
    "    for spk_idx, spk_id in enumerate(true_speakers):\n",
    "        sep_audio_path = os.path.join(\"separated_audio\", f\"spk_{spk_id}_sep_{idx}.wav\")\n",
    "        separated_waveform, sr = torchaudio.load(sep_audio_path)\n",
    "        separated_waveform = resample_to_16k(separated_waveform)\n",
    "        emb_pre = extract_embedding(pretrained_model, processor, separated_waveform, TARGET_SAMPLE_RATE_16)\n",
    "        emb_ft = extract_embedding(finetune_model, processor, separated_waveform, TARGET_SAMPLE_RATE_16)\n",
    "        pred_pre = identify_speaker(emb_pre, enrollment_embeddings_pretrained)\n",
    "        pred_ft = identify_speaker(emb_ft, enrollment_embeddings_finetuned)\n",
    "\n",
    "        if pred_pre == spk_id:\n",
    "            correct_pretrained += 1\n",
    "        if pred_ft == spk_id:\n",
    "            correct_finetuned += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T22:04:30.125598Z",
     "iopub.status.busy": "2025-04-02T22:04:30.125272Z",
     "iopub.status.idle": "2025-04-02T22:04:30.130506Z",
     "shell.execute_reply": "2025-04-02T22:04:30.129743Z",
     "shell.execute_reply.started": "2025-04-02T22:04:30.125566Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Rank-1 Identification Accuracy ---\n",
      "Pre-trained Model: 23.42%\n",
      "Fine-tuned Model: 39.9%\n"
     ]
    }
   ],
   "source": [
    "accuracy_pretrained = correct_pretrained / total if total > 0 else 0.0\n",
    "accuracy_finetuned = correct_finetuned / total if total > 0 else 0.0\n",
    "\n",
    "print(\"\\n--- Rank-1 Identification Accuracy ---\")\n",
    "print(f\"Pre-trained Model: {accuracy_pretrained * 100:.2f}%\")\n",
    "print(f\"Fine-tuned Model: {accuracy_finetuned * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7014922,
     "sourceId": 11230568,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7024971,
     "sourceId": 11243467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7025743,
     "sourceId": 11244504,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
